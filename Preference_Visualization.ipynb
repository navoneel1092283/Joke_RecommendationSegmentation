{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jR9AXrXDHeTp"
   },
   "outputs": [],
   "source": [
    "# importing the numpy library\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t_W15NXFHeTz"
   },
   "outputs": [],
   "source": [
    "# importing the pandas library\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bUKF0InAHeT0"
   },
   "outputs": [],
   "source": [
    "# importing the datasets and concatenating them into one dataframe\n",
    "\n",
    "data1 = pd.read_csv('jester-data-1.csv', header = None)\n",
    "data2 = pd.read_csv('jester-data-2.csv', header = None)\n",
    "data3 = pd.read_csv('jester-data-3.csv', header = None)\n",
    "\n",
    "\n",
    "data = pd.concat([data1, data2, data3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "plhtUiToHeT1"
   },
   "outputs": [],
   "source": [
    "# selecting the user-ratings of the fixed 100 jokes\n",
    "X = np.array(data)[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mmcrzk3zHeT2"
   },
   "outputs": [],
   "source": [
    "# 80-20 Train Test Split of the dataset\n",
    "training_set = X[0:int(0.8*73421)]\n",
    "test_set = X[int(0.8*73421):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mmZKgKTKHeT2"
   },
   "outputs": [],
   "source": [
    "# importing the PyTorch libraries for RBM Instantiation and Training\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "saWHDXOBHeT3"
   },
   "outputs": [],
   "source": [
    "# converting the training dataframe into torch tensor\n",
    "training_set = torch.FloatTensor(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A0qZ57HnHeT4"
   },
   "outputs": [],
   "source": [
    "# converting the test dataframe into torch tensor\n",
    "test_set = torch.FloatTensor(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1k-DfAm7HeT6"
   },
   "outputs": [],
   "source": [
    "# data-preprocessing of the training set\n",
    "## 1. Ratings in the range [7, 10] is set to 1\n",
    "## 2. Ratings in the range [-10, 7) is set to 0\n",
    "## 3. Missing Ratings described by 99 is set to -1\n",
    "for i in range(training_set.shape[0]):\n",
    "    for j in range(training_set.shape[1]):\n",
    "        if training_set[i,j] >= 7 and training_set[i,j] <= 10:\n",
    "            training_set[i,j] = 1\n",
    "        elif training_set[i,j] < 7:\n",
    "            training_set[i,j] = 0\n",
    "training_set[training_set == 99] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qRrqswj7HeT7"
   },
   "outputs": [],
   "source": [
    "# data-preprocessing of the test set\n",
    "## 1. Ratings in the range [7, 10] is set to 1\n",
    "## 2. Ratings in the range [-10, 7) is set to 0\n",
    "## 3. Missing Ratings described by 99 is set to -1\n",
    "for i in range(test_set.shape[0]):\n",
    "    for j in range(test_set.shape[1]):\n",
    "        if test_set[i,j] >= 7 and test_set[i,j] <= 10:\n",
    "            test_set[i,j] = 1\n",
    "        elif test_set[i,j] < 7:\n",
    "            test_set[i,j] = 0\n",
    "test_set[test_set == 99] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZwWAKlvVHeT8"
   },
   "outputs": [],
   "source": [
    "# loading the dataset, D2 i.e., the recommended ratings\n",
    "answer = np.loadtxt(\"answer.csv\", delimiter = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NnsQHhiGHeT8"
   },
   "outputs": [],
   "source": [
    "# preparing the datset, D1\n",
    "x = np.concatenate((training_set, test_set), axis = 0)\n",
    "\n",
    "for i in range(x.shape[0]):\n",
    "    for j in range(x.shape[1]):\n",
    "        if x[i,j] == -1:\n",
    "            x[i,j] = answer[i,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y6eznl2LHeUA"
   },
   "outputs": [],
   "source": [
    "# applying k-Means Clustering using 3 clusters on D1\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans = kmeans.fit(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WOFqd0_5HeUC"
   },
   "outputs": [],
   "source": [
    "# getting the predicted clusters on D2\n",
    "predictions = kmeans.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ofVaskBwHeUD"
   },
   "source": [
    "Preparaing the Preference Function Vectors for all the 3 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e-oYeIBSHeUG"
   },
   "outputs": [],
   "source": [
    "n_joke_1 = np.zeros(100)\n",
    "n_joke_2 = np.zeros(100)\n",
    "n_joke_3 = np.zeros(100)\n",
    "\n",
    "for i in range(predictions.shape[0]):\n",
    "    if predictions[i] == 0:\n",
    "        n_joke_1 += x[i]\n",
    "    elif predictions[i] == 1:\n",
    "        n_joke_2 += x[i]\n",
    "    elif predictions[i] == 2:\n",
    "        n_joke_3 += x[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z6xEKI6AHeUJ"
   },
   "outputs": [],
   "source": [
    "unique, counts = np.unique(predictions, return_counts = True)\n",
    "\n",
    "p_1 = n_joke_1/dict(zip(unique, counts))[0]\n",
    "p_2 = n_joke_2/dict(zip(unique, counts))[1]\n",
    "p_3 = n_joke_3/dict(zip(unique, counts))[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fzU_xH5wHeUK"
   },
   "outputs": [],
   "source": [
    "# saving each of the preference vectors in separate csv files\n",
    "np.savetxt(\"cluster_0_mod.csv\", p_1, delimiter = \",\")\n",
    "np.savetxt(\"cluster_1_mod.csv\", p_2, delimiter = \",\")\n",
    "np.savetxt(\"cluster_2_mod.csv\", p_3, delimiter = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BA-JhwjBHeUL"
   },
   "outputs": [],
   "source": [
    "# saving list of joke names with serial numbers in a csv file\n",
    "l = []\n",
    "for i in range(1,101):\n",
    "    label = \"Joke \" + str(i)\n",
    "    l.append(label)\n",
    "\n",
    "l = pd.Series(l)\n",
    "l.to_csv(\"l.csv\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Preference_Visualization.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
